<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <title>MASSIVE - the asm.js benchmark</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="">
    <meta name="author" content="">

    <!-- Le styles -->
    <link href="css/bootstrap.min.css" rel="stylesheet">
    <style>
      body {
        padding-top: 60px; /* 60px to make the container go all the way to the bottom of the topbar */
      }
    </style>
    <link href="css/bootstrap-responsive.min.css" rel="stylesheet">

    <!-- HTML5 shim, for IE6-8 support of HTML5 elements -->
    <!--[if lt IE 9]>
      <script src="js/html5shiv.js"></script>
    <![endif]-->
  </head>

  <body>

    <div class="navbar navbar-inverse navbar-fixed-top">
      <div class="navbar-inner">
        <div class="container">
          <button type="button" class="btn btn-navbar" data-toggle="collapse" data-target=".nav-collapse">
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </button>
          <a class="brand" href="#">MASSIVE</a>
          <div class="nav-collapse collapse">
            <ul class="nav">
              <!--li class="active"><a href="massive.html">Benchmarks</a></li-->
            </ul>
          </div><!--/.nav-collapse -->
        </div>
      </div>
    </div>

    <div class="container">

      <div class="hero-unit">
        <h1 style="color: #555">MASSIVE - the <span style="color: #000">asm.js</span> benchmark</h1>
        <h4>v0.0.4</h4>
        <br>
        <p>Massive is a JavaScript benchmark that focuses on large, real-world C++ codebases compiled into <a href="http://asmjs.org">asm.js</a> using <a href="http://emscripten.org">Emscripten</a>. This is just one pattern of JavaScript among many on the web, but is very important for things like games, and unique in that the generated JavaScript is often very large (much larger than typical JavaScript benchmarks), which is the motivation for a new benchmark.</p>
        <br>
        <p><a href="#" class="btn btn-primary btn-large " onclick="run(); return false" id="the_button">Run the benchmark now! &raquo;</a></p>
        <p id="warning"><small>(Benchmark will take a while to run, and some browsers may become less responsive for part of that time.)</small></p>
        <div id="copy_results" hidden=1>
          <center><button type="button" class="btn" onclick="alert(tableBody.innerHTML)">Copy results (so you can view them again later)</button></center>
        </div>
        <p><center style="font-weight: bold; color: #b31">This benchmark is a work in progress - it is NOT ready yet. <a style="color: #510" href="https://github.com/kripken/Massive">Feedback</a> is welcome!</center></p>
      </div>

      <div class="row-fluid" id="results_area" hidden=1>
        <div id="presentation-area"></div>
        <div class="span">
          <h3>Individual Benchmark Results</h3>
            <table class="table table-striped table-bordered table-hover">
              <thead>
                <tr>
                  <th>Benchmark</th>
                  <th>Result</th>
                  <th>Scale</th>
                  <th>What it measures</th>
                  <!--th>Normalized score<br>(higher is better)</th-->
                </tr>
              </thead>
              <tbody id="table_body">
              </tbody>
            </table>
        </div>
      </div>

<script>
function toggleFAQ() {
  var button = document.getElementById('faq-button');
  var faq = document.getElementById('faq');
  if (faq.style.display === 'none') {
    faq.style.display = 'block';
    button.innerHTML = 'Hide';
  } else {
    faq.style.display = 'none';
    button.innerHTML = 'Show';
  }
}
function ensureFAQ() {
  if (document.getElementById('faq').style.display === 'none') toggleFAQ();
}
</script>

      <div class="row-fluid">
        <div class="span">
          <h3>
            FAQ
            <button id="faq-button" type="button" class="btn" onclick="toggleFAQ()">Show</button>
          </h3>
        </div>
        <div id="faq" style="display: none">
          <h4>Why make a new benchmark?</h4>
          <p>asm.js appears in one test in Octane, but otherwise is not present in the main JavaScript benchmarks. And asm.js
             often appears as large source files, which can cause different performance characteristics than the typical
             small programs appearing in most benchmarks. For those reasons, a new asm.js benchmark is useful.</p>
          <h4>How does this relate to the Emscripten benchmark suite - what does this offer over that?</h4>
          <p>The <a href="http://kripken.github.io/embenchen/">Emscripten benchmark suite</a> evolved over time in order
             to benchmark Emscripten itself, and therefore mainly focused on throughput, and is runnable in both shell and
             browser. Massive, on the other hand, tests not just
             throughput but also browser responsiveness and other factors that only make sense when running in a browser, things
             not measured by the Emscripten benchmark suite (or by the main JavaScript benchmarks).</p>
          <a name="explanations"></a>
          <h4>What do the categories ("Main Thread Responsiveness", "Throughput", "Preparation", and "Variance") mean?</h4>
          <p><b>Main Thread Responsiveness</b> measures the user experience as a large codebase is loaded. What is tested is whether
             the main thread stalls as the codebase is prepared and executed for a short while. The score here can be improved
             by parsing the code off the main thread, for example. This does <b>not</b> measure how much time is spent,
             but only how responsive or unresponsive the user experience is (how much time is spent is measured by
             Preparation, and to some extent Throughput). Technically, we measure responsiveness by seeing if events on
             the main thread execute at the proper interval (as when the main thread stalls, it stalls both the user
             experience and other events).</p>
          <p><b>Throughput</b> measures how fast a large computational workload runs. This is what is typically measured by
             benchmarks. Massive's throughput tests focus on very large real-world codebases.</p>
          <p><b>Preparation</b> measures how long (in wall time) is spent to get a codebase ready to execute, before
             executing any of it. This measures how much
             time passes between adding a script tag with that code and being able to call the code (this may or may not
             cause a user-noticeable pause, depending on whether it is parsed on or off the main thread; Main Thread Responsiveness
             tests that aspect). "Preparation" is basically all the time before code is actually able to run; that may include
             parsing, conversion to bitcode, JIT compilation, etc., depending on the JS engine.</p>
          <p><b>Variance</b> measures how variable the frame rate is in an application that needs to run in each frame
             (this is important in things like games, which much finish all they need every 1/60 of a second, in order to be
             smooth). Specifically, we run many frames and then calculate the statistical variance and worst case. Note that
             one VM might have a much faster overall frame rate than another, but also more variance: in general, given two
             VMs with the same average, the one with less variance is "better" since it's smoother. But given a different mean,
             things are less clear (perhaps we are happy to get some average slowdown in order to reduce variance which can
             cause noticable but rare pauses?). Hence we measure variance separately from throughput (which is a measurement of the total
             speed, and is proportional to the average).</p>
          <h4>How consistent are these results between runs of the benchmark suite?</h4>
          <p>Most of the tests, in particular the throughput ones, are generally very consistent, as we run a deterministic workload
             in a web worker, which minimizes outside noise. We also run a few repetitions and average the results. However, in particular
             the Main Thread Responsiveness tests need to run on the main thread, and they involve DOM events like adding a script tag,
             setInterval, etc., which can be fairly variable. We run a larger amount of repetitions on those tests to average out the
             noise, but even so they appear to be less consistent between runs on some browsers.</p>
          <a name="toovariable"></a>
          <p>When we see the results of a test are too variable, we mark it with <b>"(Â±X%!)"</b> next to the score. The cause of such variability
             might be something else on your machine (perhaps a background indexing service happend to use a CPU core during a test, etc.),
             or it might be that the browser behaves unpredictably for some reason.</p>
        </div>
        <br>
        <div class="span">
          <center><button type="button" class="btn" onclick="flushTable(prompt('Paste the old results:'))">Enter data copied from another run</button></center>
          <br>
        </div>
      </div>

    </div> <!-- /container -->

    <script src="driver.js"></script>

    <a href="https://github.com/kripken/Massive"><img style="position: absolute; top: 35px; right: 0; border: 0;" src="https://s3.amazonaws.com/github/ribbons/forkme_right_darkblue_121621.png" alt="Fork me on GitHub"></a>

  </body>
</html>

